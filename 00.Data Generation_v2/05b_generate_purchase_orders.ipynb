{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a6ed4e-c57c-42f6-a1b9-a3b26b06a176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, sum as _sum, year, from_unixtime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import random\n",
    "\n",
    "# -------------------- KEY VARIABLES -------------------- #\n",
    "catalog = 'fin_demo'\n",
    "directory = f\"/Volumes/{catalog}/fin/data_gen_outputs\"\n",
    "output_path = f\"{directory}/purchase_orders\"\n",
    "\n",
    "# Number of months to generate (from 2023 to present)\n",
    "start_year = 2023\n",
    "start_date = datetime(start_year, 1, 1)\n",
    "end_date = datetime.now()\n",
    "num_months = (end_date.year - start_year) * 12 + end_date.month - start_date.month + 1\n",
    "\n",
    "# Records per month range\n",
    "records_per_month_min = 50000\n",
    "records_per_month_max = 100000\n",
    "\n",
    "# scale aggregate target: .5 Billion dollars (NOT YEARLY TARGET - STATS ARE WEIRD)\n",
    "# scale target .5 billion dollars = ~1.2 billion dollars\n",
    "scale_target = 500_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561bdf80-1dc1-4bbd-84e9-293a41e61184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate synthetic data for the purchase_orders table.\n",
    "This script uses PySpark with distributed compute for high-volume data generation.\n",
    "Data is partitioned by purchase order month with 50K-100K records per partition.\n",
    "Generates purchase orders starting from 2023.\n",
    "\"\"\"\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"purchase_order_id\", LongType(), nullable=False),\n",
    "    StructField(\"contract_id\", LongType(), nullable=True),\n",
    "    StructField(\"purchase_order_number\", StringType(), nullable=False),\n",
    "    StructField(\"purchase_order_date\", LongType(), nullable=False),\n",
    "    StructField(\"purchase_order_status\", StringType(), nullable=False),\n",
    "    StructField(\"supplier_id\", LongType(), nullable=False),\n",
    "    StructField(\"purchase_order_currency\", StringType(), nullable=False),\n",
    "    StructField(\"purchase_order_amount\", DoubleType(), nullable=False),\n",
    "    StructField(\"total_purchase_order_value\", DoubleType(), nullable=False),\n",
    "    StructField(\"coa_id\", LongType(), nullable=False)\n",
    "])\n",
    "\n",
    "# Enum values from schema\n",
    "PO_STATUS = [\"draft\", \"approved\", \"issued\", \"partially_received\", \"closed\", \"cancelled\"]\n",
    "\n",
    "def generate_po_amount(target_avg):\n",
    "    \"\"\"Generate realistic PO amounts.\"\"\"\n",
    "    # Use lognormal distribution to get variety but bias towards lower values\n",
    "    amount = random.lognormvariate(0, 1.5) * float(target_avg)\n",
    "    return float(round(max(100.0, min(amount, target_avg * 100)), 2))\n",
    "\n",
    "def generate_po_status(po_date_ts):\n",
    "    \"\"\"Generate PO status based on how long ago the PO was created.\"\"\"\n",
    "    current_ts = int(datetime.now().timestamp())\n",
    "    days_since_po = (current_ts - po_date_ts) / (24 * 60 * 60)\n",
    "\n",
    "    if days_since_po < 0:\n",
    "        # Future PO\n",
    "        return random.choice([\"draft\", \"approved\"])\n",
    "    elif days_since_po < 7:\n",
    "        # Very recent\n",
    "        return random.choices([\"draft\", \"approved\", \"issued\"], weights=[10, 40, 50])[0]\n",
    "    elif days_since_po < 30:\n",
    "        # Recent\n",
    "        return random.choices([\"approved\", \"issued\", \"partially_received\"], weights=[5, 50, 45])[0]\n",
    "    elif days_since_po < 90:\n",
    "        # Not too old\n",
    "        return random.choices([\"issued\", \"partially_received\", \"closed\"], weights=[10, 60, 30])[0]\n",
    "    else:\n",
    "        # Old\n",
    "        return random.choices([\"partially_received\", \"closed\", \"cancelled\"], weights=[10, 85, 5])[0]\n",
    "\n",
    "# Generate data\n",
    "print(f\"Generating purchase orders from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Target: {records_per_month_min:,}-{records_per_month_max:,} records per month\")\n",
    "print(f\"Annual PO target: ${scale_target:,.2f}\")\n",
    "\n",
    "# Read reference data\n",
    "print(\"\\nReading reference data...\")\n",
    "contracts_df = spark.read.json(f\"{directory}/inbound_contracts\")\n",
    "suppliers_df = spark.read.json(f\"{directory}/suppliers\")\n",
    "coa_df = spark.read.json(f\"{directory}/coa_hierarchy\")\n",
    "\n",
    "# Collect reference data\n",
    "contracts_data = [\n",
    "    {\n",
    "        'contract_id': row.contract_id,\n",
    "        'supplier_id': row.supplier_id,\n",
    "        'start_date': row.contract_start_date,\n",
    "        'end_date': row.estimated_completion_date,\n",
    "        'total_value': row.total_contract_value,\n",
    "        'age_days': (datetime.now().timestamp() - row.contract_start_date) / 86400\n",
    "    }\n",
    "    for row in contracts_df.select(\n",
    "        \"contract_id\",\n",
    "        \"supplier_id\",\n",
    "        \"contract_start_date\",\n",
    "        \"estimated_completion_date\",\n",
    "        \"total_contract_value\"\n",
    "    ).collect()\n",
    "]\n",
    "\n",
    "supplier_ids = [row.supplier_id for row in suppliers_df.select(\"supplier_id\").collect()]\n",
    "coa_ids = [row.coa_id for row in coa_df.select(\"coa_id\").collect()]\n",
    "\n",
    "print(f\"Loaded {len(contracts_data)} contracts\")\n",
    "print(f\"Loaded {len(supplier_ids)} suppliers\")\n",
    "print(f\"Loaded {len(coa_ids)} COA entries\")\n",
    "\n",
    "# Calculate target average PO amount\n",
    "estimated_total_pos = num_months * ((records_per_month_min + records_per_month_max) / 2)\n",
    "target_avg_amount = (scale_target * (num_months / 12)) / estimated_total_pos\n",
    "\n",
    "print(f\"\\nTarget average PO amount: ${target_avg_amount:.2f}\")\n",
    "\n",
    "# Track contract utilization\n",
    "contract_tracker = {c['contract_id']: 0 for c in contracts_data}\n",
    "contract_po_count = {c['contract_id']: 0 for c in contracts_data}\n",
    "\n",
    "print(f\"\\nAll {len(contracts_data)} contracts available for PO assignment\")\n",
    "\n",
    "po_id = 50000000  # Start with 8-digit ID\n",
    "\n",
    "# Generate and write POs month by month\n",
    "current_date = start_date\n",
    "total_records_generated = 0\n",
    "\n",
    "for month_idx in range(num_months):\n",
    "    # Calculate month boundaries\n",
    "    month_start = current_date\n",
    "    month_end = month_start + relativedelta(months=1) - timedelta(seconds=1)\n",
    "\n",
    "    month_start_ts = int(month_start.timestamp())\n",
    "    month_end_ts = int(month_end.timestamp())\n",
    "\n",
    "    # Random number of records for this month\n",
    "    num_records = random.randint(records_per_month_min, records_per_month_max)\n",
    "\n",
    "    print(f\"Month {month_idx + 1}/{num_months}: {month_start.strftime('%Y-%m')} - {num_records:,} records\")\n",
    "\n",
    "    # Filter contracts active in this month that can still accept POs\n",
    "    active_contracts = []\n",
    "    for c in contracts_data:\n",
    "        if c['start_date'] <= month_end_ts and c['end_date'] >= month_start_ts:\n",
    "            contract_id = c['contract_id']\n",
    "\n",
    "            # Calculate age-based utilization target\n",
    "            contract_age_days = c['age_days']\n",
    "            max_age = max([c['age_days'] for c in contracts_data]) if contracts_data else 1\n",
    "\n",
    "            if max_age > 0 and contract_age_days >= 0:\n",
    "                age_factor = min(contract_age_days / max_age, 1.0)\n",
    "                # Newer contracts: 50-75% target, Older contracts: 75-95% target\n",
    "                utilization_target = 0.5 + (age_factor * 0.45)\n",
    "            else:\n",
    "                utilization_target = 0.75\n",
    "\n",
    "            current_utilization = contract_tracker[contract_id] / c['total_value'] if c['total_value'] > 0 else 0\n",
    "\n",
    "            # Only include if not yet at 95% of contract value\n",
    "            if current_utilization < 0.95:\n",
    "                active_contracts.append(c)\n",
    "\n",
    "    # Generate POs\n",
    "    month_pos = []\n",
    "\n",
    "    # 60% of POs should have associated contract (from spec)\n",
    "    num_with_contract = int(num_records * 0.6)\n",
    "    num_without_contract = num_records - num_with_contract\n",
    "\n",
    "    # POs with contracts\n",
    "    pos_created_with_contract = 0\n",
    "    for i in range(num_with_contract):\n",
    "        if not active_contracts:\n",
    "            # No more contracts available, rest will be without contract\n",
    "            print(f\"  Note: Ran out of available contracts, creating {num_with_contract - i} additional POs without contracts\")\n",
    "            break\n",
    "\n",
    "        # Select contract\n",
    "        contract = random.choice(active_contracts)\n",
    "        contract_id = contract['contract_id']\n",
    "        supplier_id = contract['supplier_id']\n",
    "\n",
    "        # PO date within contract period AND month\n",
    "        contract_start = max(contract['start_date'], month_start_ts)\n",
    "        contract_end = min(contract['end_date'], month_end_ts)\n",
    "\n",
    "        if contract_end <= contract_start:\n",
    "            continue\n",
    "\n",
    "        contract_duration = contract_end - contract_start\n",
    "        random_offset = random.randint(0, max(1, int(contract_duration)))\n",
    "        po_date = contract_start + random_offset\n",
    "\n",
    "        # Calculate PO amount with age-based utilization\n",
    "        current_total = contract_tracker[contract_id]\n",
    "        remaining = contract['total_value'] - current_total\n",
    "\n",
    "        if remaining <= 0:\n",
    "            # Contract fully utilized, skip\n",
    "            continue\n",
    "\n",
    "        # Calculate age-based utilization target\n",
    "        contract_age_days = contract['age_days']\n",
    "        max_age = max([c['age_days'] for c in contracts_data]) if contracts_data else 1\n",
    "\n",
    "        if max_age > 0 and contract_age_days >= 0:\n",
    "            age_factor = min(contract_age_days / max_age, 1.0)\n",
    "            # Newer contracts: 50-75% target, Older contracts: 75-95% target\n",
    "            utilization_target = 0.5 + (age_factor * 0.45)\n",
    "        else:\n",
    "            utilization_target = 0.75\n",
    "\n",
    "        max_allowed = contract['total_value'] * utilization_target\n",
    "\n",
    "        # Check if we should add more to this contract\n",
    "        # Allow some variance but generally respect the utilization target\n",
    "        if current_total < max_allowed or random.random() < 0.2:  # 20% chance to go beyond target (but not beyond contract value)\n",
    "            # Generate amount that doesn't exceed remaining\n",
    "            base_amount = generate_po_amount(target_avg_amount)\n",
    "            po_amount = float(min(base_amount, remaining))\n",
    "\n",
    "            contract_tracker[contract_id] += po_amount\n",
    "        else:\n",
    "            # This contract has reached its target utilization for now\n",
    "            continue\n",
    "\n",
    "        # Generate unique PO number (po_id is already unique)\n",
    "        po_number = f\"PO{po_id}\"\n",
    "\n",
    "        # PO status based on date\n",
    "        po_status = generate_po_status(po_date)\n",
    "\n",
    "        coa_id = random.choice(coa_ids)\n",
    "\n",
    "        month_pos.append({\n",
    "            \"purchase_order_id\": po_id,\n",
    "            \"contract_id\": contract_id,\n",
    "            \"purchase_order_number\": po_number,\n",
    "            \"purchase_order_date\": po_date,\n",
    "            \"purchase_order_status\": po_status,\n",
    "            \"supplier_id\": supplier_id,\n",
    "            \"purchase_order_currency\": \"USD\",\n",
    "            \"purchase_order_amount\": po_amount,\n",
    "            \"total_purchase_order_value\": po_amount,  # Same as amount\n",
    "            \"coa_id\": coa_id\n",
    "        })\n",
    "\n",
    "        po_id += 1\n",
    "        pos_created_with_contract += 1\n",
    "\n",
    "    # Adjust num_without_contract to make up for any shortfall\n",
    "    actual_without_contract = num_records - pos_created_with_contract\n",
    "\n",
    "    # POs without contracts\n",
    "    for i in range(actual_without_contract):\n",
    "        random_offset = random.randint(0, int((month_end_ts - month_start_ts)))\n",
    "        po_date = month_start_ts + random_offset\n",
    "\n",
    "        supplier_id = random.choice(supplier_ids)\n",
    "        coa_id = random.choice(coa_ids)\n",
    "        po_amount = generate_po_amount(target_avg_amount)\n",
    "\n",
    "        # Generate unique PO number (po_id is already unique)\n",
    "        po_number = f\"PO{po_id}\"\n",
    "\n",
    "        po_status = generate_po_status(po_date)\n",
    "\n",
    "        month_pos.append({\n",
    "            \"purchase_order_id\": po_id,\n",
    "            \"contract_id\": None,\n",
    "            \"purchase_order_number\": po_number,\n",
    "            \"purchase_order_date\": po_date,\n",
    "            \"purchase_order_status\": po_status,\n",
    "            \"supplier_id\": supplier_id,\n",
    "            \"purchase_order_currency\": \"USD\",\n",
    "            \"purchase_order_amount\": po_amount,\n",
    "            \"total_purchase_order_value\": po_amount,\n",
    "            \"coa_id\": coa_id\n",
    "        })\n",
    "\n",
    "        po_id += 1\n",
    "\n",
    "    # Create DataFrame for this month\n",
    "    if month_pos:\n",
    "        month_df = spark.createDataFrame(month_pos, schema=schema)\n",
    "\n",
    "        # Write this month's data\n",
    "        year_str = month_start.strftime('%Y')\n",
    "        month_str = month_start.strftime('%m')\n",
    "        month_filename = f\"purchase_orders_{year_str}_{month_str}\"\n",
    "        month_output_path = f\"{output_path}/{month_filename}\"\n",
    "\n",
    "        print(f\"  Writing to {month_filename}/ ({len(month_pos):,} records)\")\n",
    "\n",
    "        month_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(month_output_path)\n",
    "\n",
    "        total_records_generated += len(month_pos)\n",
    "\n",
    "    # Move to next month\n",
    "    current_date = current_date + relativedelta(months=1)\n",
    "\n",
    "print(f\"\\n\\nTotal purchase orders generated: {total_records_generated:,}\")\n",
    "\n",
    "# Read back the data for statistics\n",
    "print(\"\\nReading generated data for statistics...\")\n",
    "df = spark.read.option(\"header\", \"true\").csv(f\"{output_path}/*/*.csv\")\n",
    "\n",
    "# Convert columns to proper types\n",
    "df = df.withColumn(\"purchase_order_amount\", col(\"purchase_order_amount\").cast(\"double\"))\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample of generated data:\")\n",
    "df.show(20, truncate=False)\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nTotal records: {df.count():,}\")\n",
    "print(f\"Unique PO IDs: {df.select('purchase_order_id').distinct().count():,}\")\n",
    "\n",
    "# Contract statistics\n",
    "contract_count = df.filter(col('contract_id').isNotNull()).count()\n",
    "total_count = df.count()\n",
    "if total_count > 0:\n",
    "    contract_percentage = (contract_count / total_count) * 100\n",
    "    print(f\"\\nRecords with contract: {contract_count:,} ({contract_percentage:.1f}%)\")\n",
    "    print(f\"Records without contract: {total_count - contract_count:,} ({100 - contract_percentage:.1f}%)\")\n",
    "\n",
    "# Status distribution\n",
    "print(\"\\nPO status distribution:\")\n",
    "df.groupBy(\"purchase_order_status\").count().orderBy(\"purchase_order_status\").show()\n",
    "\n",
    "# PO value by year\n",
    "print(\"\\nPO value by year:\")\n",
    "df_with_year = df.withColumn(\"year\", year(from_unixtime(col(\"purchase_order_date\"))))\n",
    "df_with_year.groupBy(\"year\").agg(_sum(\"purchase_order_amount\").alias(\"total_po_value\")).orderBy(\"year\").show()\n",
    "\n",
    "# Validate contract constraints\n",
    "print(\"\\nValidating contract constraints (PO amounts should not exceed contract value)...\")\n",
    "\n",
    "contracts_df_ref = spark.read.json(f\"{directory}/inbound_contracts\") \\\n",
    "    .select(\n",
    "        col(\"contract_id\"),\n",
    "        col(\"total_contract_value\"),\n",
    "        col(\"contract_start_date\")\n",
    "    )\n",
    "\n",
    "# Aggregate PO amounts by contract\n",
    "contract_totals = df.filter(col('contract_id').isNotNull()) \\\n",
    "    .withColumn(\"contract_id_long\", col(\"contract_id\").cast(\"long\")) \\\n",
    "    .groupBy('contract_id_long') \\\n",
    "    .agg(_sum('purchase_order_amount').alias('total_po_amount'))\n",
    "\n",
    "# Join with contract data and calculate percentage\n",
    "validation = contract_totals.join(\n",
    "    contracts_df_ref,\n",
    "    contract_totals.contract_id_long == contracts_df_ref.contract_id,\n",
    "    \"inner\"\n",
    ").withColumn('utilization_pct', (col('total_po_amount') / col('total_contract_value')) * 100) \\\n",
    " .withColumn('exceeds_limit', col('total_po_amount') > col('total_contract_value')) \\\n",
    " .withColumn('contract_age_days', (datetime.now().timestamp() - col('contract_start_date')) / 86400)\n",
    "\n",
    "print(\"\\nContract utilization (top 10 by PO amount):\")\n",
    "validation.select(\n",
    "    'contract_id',\n",
    "    'total_po_amount',\n",
    "    'total_contract_value',\n",
    "    'utilization_pct',\n",
    "    'contract_age_days',\n",
    "    'exceeds_limit'\n",
    ").orderBy(col('total_po_amount').desc()).show(10)\n",
    "\n",
    "# Count violations\n",
    "violations = validation.filter(col('exceeds_limit') == True).count()\n",
    "total_contracts_with_pos = validation.count()\n",
    "\n",
    "if violations > 0:\n",
    "    print(f\"\\n⚠ WARNING: {violations} out of {total_contracts_with_pos} contracts exceeded their contract value!\")\n",
    "else:\n",
    "    print(f\"\\n✓ All {total_contracts_with_pos} contracts are within their contract value limits\")\n",
    "\n",
    "# Show utilization distribution\n",
    "print(\"\\nContract utilization distribution:\")\n",
    "validation.selectExpr(\n",
    "    \"CASE \" +\n",
    "    \"WHEN utilization_pct < 25 THEN '0-25%' \" +\n",
    "    \"WHEN utilization_pct >= 25 AND utilization_pct < 50 THEN '25-50%' \" +\n",
    "    \"WHEN utilization_pct >= 50 AND utilization_pct < 75 THEN '50-75%' \" +\n",
    "    \"WHEN utilization_pct >= 75 AND utilization_pct < 100 THEN '75-100%' \" +\n",
    "    \"ELSE 'Above 100%' END as utilization_range\"\n",
    ").groupBy(\"utilization_range\").count().orderBy(\"utilization_range\").show()\n",
    "\n",
    "# Check age-based utilization\n",
    "print(\"\\nAge-based utilization check (newer contracts should have lower utilization):\")\n",
    "validation.selectExpr(\n",
    "    \"CASE \" +\n",
    "    \"WHEN contract_age_days < 180 THEN 'Very New (0-6mo)' \" +\n",
    "    \"WHEN contract_age_days >= 180 AND contract_age_days < 365 THEN 'New (6-12mo)' \" +\n",
    "    \"WHEN contract_age_days >= 365 AND contract_age_days < 730 THEN 'Older (1-2yr)' \" +\n",
    "    \"ELSE 'Very Old (2yr+)' END as age_range\",\n",
    "    \"utilization_pct\"\n",
    ").groupBy(\"age_range\").agg(\n",
    "    {\"utilization_pct\": \"avg\", \"utilization_pct\": \"min\", \"utilization_pct\": \"max\"}\n",
    ").orderBy(\"age_range\").show()\n",
    "\n",
    "print(\"\\nData generation complete!\")\n",
    "print(f\"\\nFiles are located in: {output_path}/\")\n",
    "print(\"Each month has its own directory with a CSV file inside\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "05b_generate_purchase_orders",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
