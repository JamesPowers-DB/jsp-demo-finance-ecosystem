{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8814b0fa-f7f4-4b6b-9689-fbfeb51c36d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, sum as _sum, year, from_unixtime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------- KEY VARIABLES -------------------- #\n",
    "catalog = 'main'\n",
    "directory = f\"/Volumes/{catalog}/finance_lakehouse/data_gen_outputs\"\n",
    "output_path = f\"{directory}/revenue_transactions\"\n",
    "\n",
    "\n",
    "# Number of months to generate (from 2023 to present)\n",
    "start_year = 2023\n",
    "start_date = datetime(start_year, 1, 1)\n",
    "end_date = datetime.now()\n",
    "num_months = (end_date.year - start_year) * 12 + end_date.month - start_date.month + 1\n",
    "\n",
    "# Records per month range\n",
    "records_per_month_min = 50000\n",
    "records_per_month_max = 100000\n",
    "\n",
    "# Annual aggregate target: 2 Billion dollars\n",
    "annual_target = 2_000_000_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc241bff-99b8-4c55-9bfe-75fcd50bac83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate synthetic data for the revenue_transactions table.\n",
    "This script uses PySpark with distributed compute for high-volume data generation.\n",
    "Data is partitioned by transaction month with 50K-100K records per partition.\n",
    "Generates revenue transactions starting from 2023.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"rev_trx_id\", LongType(), nullable=False),\n",
    "    StructField(\"contract_id\", LongType(), nullable=True),\n",
    "    StructField(\"customer_id\", LongType(), nullable=False),\n",
    "    StructField(\"transaction_date\", LongType(), nullable=False),\n",
    "    StructField(\"coa_id\", LongType(), nullable=False),\n",
    "    StructField(\"cost_category\", StringType(), nullable=False),\n",
    "    StructField(\"amount\", DoubleType(), nullable=False)\n",
    "])\n",
    "\n",
    "# Enum values from schema\n",
    "COST_CATEGORIES = [\"labor\", \"compute\", \"materials\", \"subcontractor\", \"equipment\", \"overhead\"]\n",
    "\n",
    "def generate_transaction_amount(cost_category, target_avg):\n",
    "    \"\"\"Generate realistic transaction amounts based on cost category.\"\"\"\n",
    "    ranges = {\n",
    "        \"labor\": (50.0, 5000.0),\n",
    "        \"compute\": (50.0, 5000.0),\n",
    "        \"materials\": (100.0, 50000.0),\n",
    "        \"subcontractor\": (1000.0, 100000.0),\n",
    "        \"equipment\": (500.0, 25000.0),\n",
    "        \"overhead\": (100.0, 10000.0)\n",
    "    }\n",
    "\n",
    "    min_val, max_val = ranges.get(cost_category, (100.0, 10000.0))\n",
    "    # Use lognormal distribution to get variety but bias towards lower values\n",
    "    amount = random.lognormvariate(0, 1.5) * float(target_avg)\n",
    "    return float(round(max(min_val, min(amount, max_val)), 2))\n",
    "\n",
    "# Generate data\n",
    "print(f\"Generating revenue transactions data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Target: {records_per_month_min:,}-{records_per_month_max:,} records per month\")\n",
    "print(f\"Annual revenue target: ${annual_target:,.2f}\")\n",
    "\n",
    "# Read reference data\n",
    "print(\"\\nReading reference data...\")\n",
    "contracts_df = spark.read.json(f\"{directory}/outbound_contracts\")\n",
    "customers_df = spark.read.json(f\"{directory}/customers\")\n",
    "coa_df = spark.read.json(f\"{directory}/coa_hierarchy\")\n",
    "\n",
    "# Collect reference data\n",
    "contracts_data = [\n",
    "    {\n",
    "        'contract_id': row.contract_id,\n",
    "        'customer_id': row.customer_id,\n",
    "        'start_date': row.contract_start_date,\n",
    "        'end_date': row.estimated_completion_date,\n",
    "        'total_value': row.total_contract_value,\n",
    "        'age_days': (datetime.now().timestamp() - row.contract_start_date) / 86400\n",
    "    }\n",
    "    for row in contracts_df.select(\n",
    "        \"contract_id\",\n",
    "        \"customer_id\",\n",
    "        \"contract_start_date\",\n",
    "        \"estimated_completion_date\",\n",
    "        \"total_contract_value\"\n",
    "    ).collect()\n",
    "]\n",
    "\n",
    "customer_ids = [row.customer_id for row in customers_df.select(\"customer_id\").collect()]\n",
    "coa_ids = [row.coa_id for row in coa_df.select(\"coa_id\").collect()]\n",
    "\n",
    "print(f\"Loaded {len(contracts_data)} contracts\")\n",
    "print(f\"Loaded {len(customer_ids)} customers\")\n",
    "print(f\"Loaded {len(coa_ids)} COA entries\")\n",
    "\n",
    "# Calculate target average transaction amount\n",
    "estimated_total_transactions = num_months * ((records_per_month_min + records_per_month_max) / 2)\n",
    "target_avg_amount = (annual_target * (num_months / 12)) / estimated_total_transactions\n",
    "\n",
    "print(f\"\\nTarget average transaction amount: ${target_avg_amount:.2f}\")\n",
    "\n",
    "# Track contract utilization globally\n",
    "contract_tracker = {c['contract_id']: 0 for c in contracts_data}\n",
    "\n",
    "# Select subset of contracts to have revenue (not all contracts should have revenue)\n",
    "contracts_with_revenue = random.sample(contracts_data, int(len(contracts_data) * 0.6))\n",
    "print(f\"60% of contracts ({len(contracts_with_revenue)}) will have revenue transactions\")\n",
    "\n",
    "rev_trx_id = 50000000  # Start with 8-digit ID\n",
    "\n",
    "# Generate and write transactions month by month\n",
    "current_date = start_date\n",
    "total_records_generated = 0\n",
    "\n",
    "for month_idx in range(num_months):\n",
    "    # Calculate month boundaries\n",
    "    month_start = current_date\n",
    "    month_end = month_start + relativedelta(months=1) - timedelta(seconds=1)\n",
    "\n",
    "    month_start_ts = int(month_start.timestamp())\n",
    "    month_end_ts = int(month_end.timestamp())\n",
    "\n",
    "    # Random number of records for this month\n",
    "    num_records = random.randint(records_per_month_min, records_per_month_max)\n",
    "\n",
    "    print(f\"Month {month_idx + 1}/{num_months}: {month_start.strftime('%Y-%m')} - {num_records:,} records\")\n",
    "\n",
    "    # Filter contracts active in this month\n",
    "    active_contracts = [\n",
    "        c for c in contracts_with_revenue\n",
    "        if c['start_date'] <= month_end_ts and c['end_date'] >= month_start_ts\n",
    "    ]\n",
    "\n",
    "    # Generate transactions\n",
    "    month_transactions = []\n",
    "\n",
    "    # 80% of records should have associated contract\n",
    "    num_with_contract = int(num_records * 0.8)\n",
    "    num_without_contract = num_records - num_with_contract\n",
    "\n",
    "    # Transactions with contracts\n",
    "    for i in range(num_with_contract):\n",
    "        if not active_contracts:\n",
    "            break\n",
    "\n",
    "        # Select contract with consideration for utilization\n",
    "        # Older contracts should have higher utilization\n",
    "        contract = random.choice(active_contracts)\n",
    "        contract_id = contract['contract_id']\n",
    "        customer_id = contract['customer_id']\n",
    "\n",
    "        # Transaction date within contract period AND month\n",
    "        contract_start = max(contract['start_date'], month_start_ts)\n",
    "        contract_end = min(contract['end_date'], month_end_ts)\n",
    "\n",
    "        if contract_end <= contract_start:\n",
    "            continue\n",
    "\n",
    "        contract_duration = contract_end - contract_start\n",
    "        random_offset = random.randint(0, max(1, int(contract_duration)))\n",
    "        transaction_date = contract_start + random_offset\n",
    "\n",
    "        # Calculate utilization target based on contract age\n",
    "        # Newer contracts: lower utilization, Older contracts: higher utilization\n",
    "        contract_age_days = contract['age_days']\n",
    "        max_age = max([c['age_days'] for c in contracts_with_revenue])\n",
    "\n",
    "        if max_age > 0:\n",
    "            age_factor = contract_age_days / max_age\n",
    "            utilization_target = 0.5 + (age_factor * 0.5)  # 50% to 100% utilization\n",
    "        else:\n",
    "            utilization_target = 0.75\n",
    "\n",
    "        max_allowed = contract['total_value'] * utilization_target\n",
    "        current_total = contract_tracker[contract_id]\n",
    "\n",
    "        # Don't exceed contract value\n",
    "        if current_total >= contract['total_value']:\n",
    "            continue\n",
    "\n",
    "        # Generate amount\n",
    "        coa_id = random.choice(coa_ids)\n",
    "        cost_category = random.choice(COST_CATEGORIES)\n",
    "        base_amount = generate_transaction_amount(cost_category, target_avg_amount)\n",
    "\n",
    "        # Ensure we don't exceed contract value\n",
    "        remaining = float(contract['total_value'] - current_total)\n",
    "        amount = float(min(base_amount, remaining))\n",
    "\n",
    "        if amount <= 0:\n",
    "            continue\n",
    "\n",
    "        contract_tracker[contract_id] += amount\n",
    "\n",
    "        month_transactions.append({\n",
    "            \"rev_trx_id\": rev_trx_id,\n",
    "            \"contract_id\": contract_id,\n",
    "            \"customer_id\": customer_id,\n",
    "            \"transaction_date\": transaction_date,\n",
    "            \"coa_id\": coa_id,\n",
    "            \"cost_category\": cost_category,\n",
    "            \"amount\": float(round(amount, 2))\n",
    "        })\n",
    "\n",
    "        rev_trx_id += 1\n",
    "\n",
    "    # Transactions without contracts\n",
    "    for i in range(num_without_contract):\n",
    "        random_offset = random.randint(0, int((month_end_ts - month_start_ts)))\n",
    "        transaction_date = month_start_ts + random_offset\n",
    "\n",
    "        customer_id = random.choice(customer_ids)\n",
    "        coa_id = random.choice(coa_ids)\n",
    "        cost_category = random.choice(COST_CATEGORIES)\n",
    "        amount = generate_transaction_amount(cost_category, target_avg_amount)\n",
    "\n",
    "        month_transactions.append({\n",
    "            \"rev_trx_id\": rev_trx_id,\n",
    "            \"contract_id\": None,\n",
    "            \"customer_id\": customer_id,\n",
    "            \"transaction_date\": transaction_date,\n",
    "            \"coa_id\": coa_id,\n",
    "            \"cost_category\": cost_category,\n",
    "            \"amount\": float(round(amount, 2))\n",
    "        })\n",
    "\n",
    "        rev_trx_id += 1\n",
    "\n",
    "    # Create DataFrame for this month\n",
    "    if month_transactions:\n",
    "        month_df = spark.createDataFrame(month_transactions, schema=schema)\n",
    "\n",
    "        # Write this month's data\n",
    "        year_str = month_start.strftime('%Y')\n",
    "        month_str = month_start.strftime('%m')\n",
    "        month_filename = f\"revenue_transactions_{year_str}_{month_str}\"\n",
    "        month_output_path = f\"{output_path}/{month_filename}\"\n",
    "\n",
    "        print(f\"  Writing to {month_filename}/ ({len(month_transactions):,} records)\")\n",
    "\n",
    "        month_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(month_output_path)\n",
    "\n",
    "        total_records_generated += len(month_transactions)\n",
    "\n",
    "    # Move to next month\n",
    "    current_date = current_date + relativedelta(months=1)\n",
    "\n",
    "print(f\"\\n\\nTotal transactions generated: {total_records_generated:,}\")\n",
    "\n",
    "# Read back the data for statistics\n",
    "print(\"\\nReading generated data for statistics...\")\n",
    "df = spark.read.option(\"header\", \"true\").csv(f\"{output_path}/*/*.csv\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample of generated data:\")\n",
    "df.show(20, truncate=False)\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nTotal records: {df.count():,}\")\n",
    "print(f\"Unique transaction IDs: {df.select('rev_trx_id').distinct().count():,}\")\n",
    "\n",
    "# Contract statistics\n",
    "contract_count = df.filter(col('contract_id').isNotNull()).count()\n",
    "total_count = df.count()\n",
    "if total_count > 0:\n",
    "    contract_percentage = (contract_count / total_count) * 100\n",
    "    print(f\"\\nRecords with contract: {contract_count:,} ({contract_percentage:.1f}%)\")\n",
    "    print(f\"Records without contract: {total_count - contract_count:,} ({100 - contract_percentage:.1f}%)\")\n",
    "\n",
    "# Category distribution\n",
    "print(\"\\nCost category distribution:\")\n",
    "df.groupBy(\"cost_category\").count().orderBy(\"cost_category\").show()\n",
    "\n",
    "# Revenue by year\n",
    "print(\"\\nRevenue by year:\")\n",
    "df_with_year = df.withColumn(\"year\", year(from_unixtime(col(\"transaction_date\"))))\n",
    "df_with_year.groupBy(\"year\").agg(_sum(\"amount\").alias(\"total_revenue\")).orderBy(\"year\").show()\n",
    "\n",
    "# Validate contract constraints\n",
    "print(\"\\nValidating contract constraints (revenue should not exceed contract value)...\")\n",
    "\n",
    "contracts_df_ref = spark.read.json(f\"{directory}/outbound_contracts\") \\\n",
    "    .select(\n",
    "        col(\"contract_id\"),\n",
    "        col(\"total_contract_value\")\n",
    "    )\n",
    "\n",
    "# Aggregate revenue by contract\n",
    "contract_totals = df.filter(col('contract_id').isNotNull()) \\\n",
    "    .groupBy('contract_id') \\\n",
    "    .agg(_sum('amount').alias('total_revenue'))\n",
    "\n",
    "# Join with contract data and calculate percentage\n",
    "validation = contract_totals.join(contracts_df_ref, \"contract_id\", \"inner\") \\\n",
    "    .withColumn('utilization_pct', (col('total_revenue') / col('total_contract_value')) * 100) \\\n",
    "    .withColumn('exceeds_limit', col('total_revenue') > col('total_contract_value'))\n",
    "\n",
    "print(\"\\nContract utilization (top 10 by revenue):\")\n",
    "validation.select(\n",
    "    'contract_id',\n",
    "    'total_revenue',\n",
    "    'total_contract_value',\n",
    "    'utilization_pct',\n",
    "    'exceeds_limit'\n",
    ").orderBy(col('total_revenue').desc()).show(10)\n",
    "\n",
    "# Count violations\n",
    "violations = validation.filter(col('exceeds_limit') == True).count()\n",
    "total_contracts_with_revenue = validation.count()\n",
    "\n",
    "if violations > 0:\n",
    "    print(f\"\\n⚠ WARNING: {violations} out of {total_contracts_with_revenue} contracts exceeded their contract value!\")\n",
    "else:\n",
    "    print(f\"\\n✓ All {total_contracts_with_revenue} contracts are within their contract value limits\")\n",
    "\n",
    "# Show utilization distribution\n",
    "print(\"\\nContract utilization distribution:\")\n",
    "validation.selectExpr(\n",
    "    \"CASE \" +\n",
    "    \"WHEN utilization_pct < 25 THEN '0-25%' \" +\n",
    "    \"WHEN utilization_pct >= 25 AND utilization_pct < 50 THEN '25-50%' \" +\n",
    "    \"WHEN utilization_pct >= 50 AND utilization_pct < 75 THEN '50-75%' \" +\n",
    "    \"WHEN utilization_pct >= 75 AND utilization_pct < 100 THEN '75-100%' \" +\n",
    "    \"ELSE 'Above 100%' END as utilization_range\"\n",
    ").groupBy(\"utilization_range\").count().orderBy(\"utilization_range\").show()\n",
    "\n",
    "print(\"\\nData generation complete!\")\n",
    "print(f\"\\nFiles are located in: {output_path}/\")\n",
    "print(\"Each month has its own directory with a CSV file inside\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47c0c8d0-b027-48bf-9f65-4bcbb7a0f2c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04c_generate_rev_transactions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
