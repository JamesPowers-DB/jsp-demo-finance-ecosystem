{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2116f17b-0b95-49ed-83db-f430681191d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS jsp_demo;\n",
    "CREATE SCHEMA IF NOT EXISTS jsp_demo.fin;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15efa0db-7e83-4614-92f0-6d2bcc36e44f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ============================================================================\n",
    "# COMPANY PROFILE\n",
    "# ============================================================================\n",
    "\n",
    "COMPANY_NAME = \"GlobalBuild Construction Inc.\"\n",
    "INDUSTRY = \"Construction & Engineering\"\n",
    "FISCAL_YEAR_END = \"December 31\"\n",
    "BASE_ANNUAL_REVENUE = 10_000_000_000  # $10B\n",
    "YOY_GROWTH_RATE = 0.05  # 5% annual growth\n",
    "NUM_MONTHS = 48\n",
    "\n",
    "# Legal Entities\n",
    "LEGAL_ENTITIES = {\n",
    "    'GB-US': {'name': 'GlobalBuild Americas Inc.', 'continent': 'Americas', 'currency': 'USD', 'revenue_split': 0.60},\n",
    "    'GB-EU': {'name': 'GlobalBuild EMEA Ltd.', 'continent': 'EMEA', 'currency': 'EUR', 'revenue_split': 0.40}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df5d442-d50c-4f7f-9739-5f147f2ff5b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. GENERATE 48-MONTH INCOME STATEMENT\n",
    "# ============================================================================\n",
    "\n",
    "def generate_income_statement(start_date='2021-09-01', num_months=48):\n",
    "    \"\"\"Generate monthly P&L for a construction company using PySpark\"\"\"\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    # Generate date sequence\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    dates = [(start + relativedelta(months=i)).replace(day=1) for i in range(num_months)]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    seasonality = {\n",
    "        1: 0.85, 2: 0.88, 3: 0.95, 4: 1.05, 5: 1.10, 6: 1.12,\n",
    "        7: 1.15, 8: 1.13, 9: 1.08, 10: 1.02, 11: 0.92, 12: 0.90\n",
    "    }\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        month = date.month\n",
    "        year_progress = i / 12.0\n",
    "\n",
    "        base_monthly = BASE_ANNUAL_REVENUE / 12\n",
    "        growth_factor = (1 + YOY_GROWTH_RATE) ** year_progress\n",
    "        seasonal_factor = seasonality[month]\n",
    "\n",
    "        # Using random with fixed seed\n",
    "        random.seed(42 + i)\n",
    "        revenue = base_monthly * growth_factor * seasonal_factor * (0.97 + random.random() * 0.06)\n",
    "\n",
    "        cogs_rate = 0.76 + random.random() * 0.03\n",
    "        cogs = revenue * cogs_rate\n",
    "        gross_profit = revenue - cogs\n",
    "\n",
    "        sg_and_a = revenue * (0.10 + random.random() * 0.02)\n",
    "        sales_marketing = revenue * (0.03 + random.random() * 0.01)\n",
    "        rd_expense = revenue * (0.005 + random.random() * 0.005)\n",
    "\n",
    "        total_opex = sg_and_a + sales_marketing + rd_expense\n",
    "        ebitda = gross_profit - total_opex\n",
    "\n",
    "        depreciation = revenue * (0.015 + random.random() * 0.01)\n",
    "        ebit = ebitda - depreciation\n",
    "\n",
    "        interest_expense = revenue * (0.008 + random.random() * 0.004)\n",
    "        ebt = ebit - interest_expense\n",
    "\n",
    "        tax_rate = 0.24\n",
    "        tax_expense = max(0, ebt * tax_rate)\n",
    "        net_income = ebt - tax_expense\n",
    "\n",
    "        data.append({\n",
    "            'period': date.strftime('%Y-%m'),\n",
    "            'fiscal_year': date.year if date.month >= 1 else date.year - 1,\n",
    "            'fiscal_quarter': f\"Q{(date.month-1)//3 + 1}\",\n",
    "            'fiscal_month': date.month,\n",
    "            'revenue': round(revenue, 2),\n",
    "            'cost_of_revenue': round(cogs, 2),\n",
    "            'gross_profit': round(gross_profit, 2),\n",
    "            'gross_margin_pct': round((gross_profit / revenue) * 100, 2),\n",
    "            'sg_and_a': round(sg_and_a, 2),\n",
    "            'sales_and_marketing': round(sales_marketing, 2),\n",
    "            'research_and_development': round(rd_expense, 2),\n",
    "            'total_operating_expenses': round(total_opex, 2),\n",
    "            'ebitda': round(ebitda, 2),\n",
    "            'ebitda_margin_pct': round((ebitda / revenue) * 100, 2),\n",
    "            'depreciation_and_amortization': round(depreciation, 2),\n",
    "            'ebit': round(ebit, 2),\n",
    "            'interest_expense': round(interest_expense, 2),\n",
    "            'ebt': round(ebt, 2),\n",
    "            'tax_expense': round(tax_expense, 2),\n",
    "            'net_income': round(net_income, 2),\n",
    "            'net_margin_pct': round((net_income / revenue) * 100, 2)\n",
    "        })\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('period', StringType(), True),\n",
    "        StructField('fiscal_year', IntegerType(), True),\n",
    "        StructField('fiscal_quarter', StringType(), True),\n",
    "        StructField('fiscal_month', IntegerType(), True),\n",
    "        StructField('revenue', DoubleType(), True),\n",
    "        StructField('cost_of_revenue', DoubleType(), True),\n",
    "        StructField('gross_profit', DoubleType(), True),\n",
    "        StructField('gross_margin_pct', DoubleType(), True),\n",
    "        StructField('sg_and_a', DoubleType(), True),\n",
    "        StructField('sales_and_marketing', DoubleType(), True),\n",
    "        StructField('research_and_development', DoubleType(), True),\n",
    "        StructField('total_operating_expenses', DoubleType(), True),\n",
    "        StructField('ebitda', DoubleType(), True),\n",
    "        StructField('ebitda_margin_pct', DoubleType(), True),\n",
    "        StructField('depreciation_and_amortization', DoubleType(), True),\n",
    "        StructField('ebit', DoubleType(), True),\n",
    "        StructField('interest_expense', DoubleType(), True),\n",
    "        StructField('ebt', DoubleType(), True),\n",
    "        StructField('tax_expense', DoubleType(), True),\n",
    "        StructField('net_income', DoubleType(), True),\n",
    "        StructField('net_margin_pct', DoubleType(), True)\n",
    "    ])\n",
    "\n",
    "    return spark.createDataFrame(data, schema)\n",
    "\n",
    "income_statement = generate_income_statement()\n",
    "income_statement.writeTo(\"jsp_demo.fin.income_statement\").createOrReplace()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4892a32e-f1ee-4e16-b032-47b897bfa30d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. CHART OF ACCOUNTS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_chart_of_accounts():\n",
    "    \"\"\"Create Chart of Accounts with dimensional model using PySpark\"\"\"\n",
    "\n",
    "    accounts = []\n",
    "    account_id = 1000\n",
    "\n",
    "    account_categories = {\n",
    "        'Revenue': [\n",
    "            ('4100', 'Project Revenue - Commercial', 'Revenue'),\n",
    "            ('4110', 'Project Revenue - Residential', 'Revenue'),\n",
    "            ('4120', 'Project Revenue - Infrastructure', 'Revenue'),\n",
    "            ('4130', 'Project Revenue - Industrial', 'Revenue'),\n",
    "            ('4200', 'Change Order Revenue', 'Revenue'),\n",
    "            ('4300', 'Service Revenue', 'Revenue'),\n",
    "        ],\n",
    "        'Cost of Revenue': [\n",
    "            ('5100', 'Direct Labor', 'COGS'),\n",
    "            ('5200', 'Materials and Supplies', 'COGS'),\n",
    "            ('5300', 'Subcontractor Costs', 'COGS'),\n",
    "            ('5400', 'Equipment Rental', 'COGS'),\n",
    "            ('5500', 'Project Site Costs', 'COGS'),\n",
    "        ],\n",
    "        'Operating Expenses': [\n",
    "            ('6100', 'Salaries and Wages - Admin', 'OPEX'),\n",
    "            ('6110', 'Salaries and Wages - Management', 'OPEX'),\n",
    "            ('6200', 'Employee Benefits', 'OPEX'),\n",
    "            ('6300', 'Office Rent and Utilities', 'OPEX'),\n",
    "            ('6400', 'Professional Services', 'OPEX'),\n",
    "            ('6500', 'Insurance', 'OPEX'),\n",
    "            ('6600', 'Marketing and Business Development', 'OPEX'),\n",
    "            ('6700', 'Travel and Entertainment', 'OPEX'),\n",
    "            ('6800', 'Technology and Software', 'OPEX'),\n",
    "            ('6900', 'Office Supplies', 'OPEX'),\n",
    "        ],\n",
    "        'Assets': [\n",
    "            ('1100', 'Cash and Cash Equivalents', 'Asset'),\n",
    "            ('1200', 'Accounts Receivable', 'Asset'),\n",
    "            ('1300', 'Inventory - Materials', 'Asset'),\n",
    "            ('1400', 'Prepaid Expenses', 'Asset'),\n",
    "            ('1500', 'Property Plant and Equipment', 'Asset'),\n",
    "            ('1510', 'Accumulated Depreciation', 'Asset'),\n",
    "            ('1600', 'Construction Equipment', 'Asset'),\n",
    "            ('1610', 'Accumulated Depreciation - Equipment', 'Asset'),\n",
    "        ],\n",
    "        'Liabilities': [\n",
    "            ('2100', 'Accounts Payable', 'Liability'),\n",
    "            ('2200', 'Accrued Expenses', 'Liability'),\n",
    "            ('2300', 'Deferred Revenue', 'Liability'),\n",
    "            ('2400', 'Short-term Debt', 'Liability'),\n",
    "            ('2500', 'Long-term Debt', 'Liability'),\n",
    "        ],\n",
    "        'Other': [\n",
    "            ('7100', 'Depreciation Expense', 'Depreciation'),\n",
    "            ('7200', 'Amortization Expense', 'Depreciation'),\n",
    "            ('8100', 'Interest Expense', 'Interest'),\n",
    "            ('8200', 'Interest Income', 'Interest'),\n",
    "            ('9100', 'Income Tax Expense', 'Tax'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for category, accts in account_categories.items():\n",
    "        for acct_num, acct_name, acct_type in accts:\n",
    "            accounts.append({\n",
    "                'account_id': account_id,\n",
    "                'account_number': acct_num,\n",
    "                'account_name': acct_name,\n",
    "                'account_type': acct_type,\n",
    "                'account_category': category,\n",
    "                'is_active': True\n",
    "            })\n",
    "            account_id += 1\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('account_id', IntegerType(), True),\n",
    "        StructField('account_number', StringType(), True),\n",
    "        StructField('account_name', StringType(), True),\n",
    "        StructField('account_type', StringType(), True),\n",
    "        StructField('account_category', StringType(), True),\n",
    "        StructField('is_active', BooleanType(), True)\n",
    "    ])\n",
    "\n",
    "    return spark.createDataFrame(accounts, schema)\n",
    "\n",
    "chart_of_accounts = generate_chart_of_accounts()\n",
    "chart_of_accounts.writeTo(\"jsp_demo.fin.chart_of_accounts\").createOrReplace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d8510b0-05ed-48b8-8854-eaf3f970d504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. COST CENTERS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_cost_centers(num_centers=50):\n",
    "    \"\"\"Generate cost centers representing departments and divisions using PySpark\"\"\"\n",
    "\n",
    "    cost_center_types = [\n",
    "        *[('Operations', 'Project Delivery') for _ in range(15)],\n",
    "        *[('Operations', 'Site Management') for _ in range(10)],\n",
    "        *[('Operations', 'Equipment Management') for _ in range(5)],\n",
    "        *[('Corporate', 'Finance & Accounting') for _ in range(3)],\n",
    "        *[('Corporate', 'Human Resources') for _ in range(2)],\n",
    "        *[('Corporate', 'Legal & Compliance') for _ in range(2)],\n",
    "        *[('Corporate', 'IT & Technology') for _ in range(3)],\n",
    "        *[('Sales', 'Business Development') for _ in range(4)],\n",
    "        *[('Sales', 'Estimating & Bidding') for _ in range(3)],\n",
    "        *[('Support', 'Procurement') for _ in range(2)],\n",
    "        *[('Support', 'Quality & Safety') for _ in range(1)],\n",
    "    ]\n",
    "\n",
    "    cost_centers = []\n",
    "    for i, (division, function) in enumerate(cost_center_types[:num_centers], start=1):\n",
    "        cost_centers.append({\n",
    "            'cost_center_id': f'CC{i:04d}',\n",
    "            'cost_center_name': f'{function} {i:02d}',\n",
    "            'division': division,\n",
    "            'function': function,\n",
    "            'is_active': True\n",
    "        })\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('cost_center_id', StringType(), True),\n",
    "        StructField('cost_center_name', StringType(), True),\n",
    "        StructField('division', StringType(), True),\n",
    "        StructField('function', StringType(), True),\n",
    "        StructField('is_active', BooleanType(), True)\n",
    "    ])\n",
    "\n",
    "    return spark.createDataFrame(cost_centers, schema)\n",
    "\n",
    "cost_centers = generate_cost_centers(50)\n",
    "cost_centers.writeTo(\"jsp_demo.fin.cost_centers\").createOrReplace()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35d7d5d6-2a24-411c-ad08-f610f6fc4eae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. PROJECTS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_projects(num_projects=200):\n",
    "    \"\"\"Generate project master data with 80/20 rule using PySpark\"\"\"\n",
    "\n",
    "    project_types = [\n",
    "        'Commercial Office Building', 'Residential High-Rise', 'Infrastructure - Highway',\n",
    "        'Infrastructure - Bridge', 'Industrial Plant', 'Hospital', 'Educational Facility',\n",
    "        'Mixed-Use Development', 'Warehouse & Logistics', 'Retail Center'\n",
    "    ]\n",
    "\n",
    "    regions = ['North America - East', 'North America - West', 'Europe - North', 'Europe - South',\n",
    "               'Middle East', 'Asia Pacific']\n",
    "\n",
    "    projects = []\n",
    "\n",
    "    # 40 large projects (80% of revenue)\n",
    "    for i in range(1, 41):\n",
    "        random.seed(42 + i)\n",
    "        project_value = 150_000_000 + random.random() * 350_000_000\n",
    "        duration_months = random.randint(18, 48)\n",
    "        region = random.choice(regions)\n",
    "        legal_entity = 'GB-US' if 'North America' in region or 'Middle East' in region else 'GB-EU'\n",
    "        start_days = random.randint(0, 365*3)\n",
    "        start_date = (datetime(2021, 1, 1) + timedelta(days=start_days)).strftime('%Y-%m-%d')\n",
    "        status = 'Active' if datetime.strptime(start_date, '%Y-%m-%d') < datetime(2024, 1, 1) else 'Planning'\n",
    "\n",
    "        projects.append({\n",
    "            'project_id': f'PRJ{i:05d}',\n",
    "            'project_name': f'{random.choice(project_types)} - Project {i:03d}',\n",
    "            'project_type': random.choice(project_types),\n",
    "            'project_size': 'Large',\n",
    "            'region': region,\n",
    "            'legal_entity_code': legal_entity,\n",
    "            'project_value': round(project_value, 2),\n",
    "            'start_date': start_date,\n",
    "            'duration_months': duration_months,\n",
    "            'status': status,\n",
    "        })\n",
    "\n",
    "    # 160 small projects (20% of revenue)\n",
    "    for i in range(41, 201):\n",
    "        random.seed(42 + i)\n",
    "        project_value = 5_000_000 + random.random() * 45_000_000\n",
    "        duration_months = random.randint(6, 24)\n",
    "        region = random.choice(regions)\n",
    "        legal_entity = 'GB-US' if 'North America' in region or 'Middle East' in region else 'GB-EU'\n",
    "        start_days = random.randint(0, 365*3)\n",
    "        start_date = (datetime(2021, 1, 1) + timedelta(days=start_days)).strftime('%Y-%m-%d')\n",
    "        status = 'Active' if datetime.strptime(start_date, '%Y-%m-%d') < datetime(2024, 1, 1) else 'Planning'\n",
    "\n",
    "        projects.append({\n",
    "            'project_id': f'PRJ{i:05d}',\n",
    "            'project_name': f'{random.choice(project_types)} - Project {i:03d}',\n",
    "            'project_type': random.choice(project_types),\n",
    "            'project_size': 'Small',\n",
    "            'region': region,\n",
    "            'legal_entity_code': legal_entity,\n",
    "            'project_value': round(project_value, 2),\n",
    "            'start_date': start_date,\n",
    "            'duration_months': duration_months,\n",
    "            'status': status,\n",
    "        })\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('project_id', StringType(), True),\n",
    "        StructField('project_name', StringType(), True),\n",
    "        StructField('project_type', StringType(), True),\n",
    "        StructField('project_size', StringType(), True),\n",
    "        StructField('region', StringType(), True),\n",
    "        StructField('legal_entity_code', StringType(), True),\n",
    "        StructField('project_value', DoubleType(), True),\n",
    "        StructField('start_date', StringType(), True),\n",
    "        StructField('duration_months', IntegerType(), True),\n",
    "        StructField('status', StringType(), True)\n",
    "    ])\n",
    "\n",
    "    return spark.createDataFrame(projects, schema)\n",
    "\n",
    "projects = generate_projects(200)\n",
    "projects.writeTo(\"jsp_demo.fin.projects\").createOrReplace()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8321753609825162,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01_generate_company_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
